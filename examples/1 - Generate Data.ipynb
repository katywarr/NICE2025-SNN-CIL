{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44fb36e-40ea-414e-b9dd-92ce0eef230f",
   "metadata": {},
   "source": [
    "# 1. Generate Test Data\n",
    "\n",
    "Generate a dataset for using in subequent tests. Save the data.\n",
    "This is more efficient than creating the data each time and also ensures that the same data is used accross multiple tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcab5df1-0ba7-4b47-9d62-b3503e7ebe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from utils.mnist_reader import get_and_save_train_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca7e71d-e26a-43df-a07e-0df8fd3a2764",
   "metadata": {},
   "source": [
    "## Specify the data requirements\n",
    "\n",
    "Specify the problem space for this test, the appropriate training and test data will be generated.\n",
    "\n",
    "The problem space describes the data that will be generated. \n",
    "* `dataset`: The name of the openml dataset to use. For example, `mnist_784` or `fashion-MNIST`. The number of features `n` in **Table 1** in the paper is derived from the data.\n",
    "* `precision_required`: The number of possible discrete values excluding zero that can be assigned to a feature. This is `d-1`in **Table 1** in the paper.\n",
    "* `trains_per_class`: The number of training examples from each class.\n",
    "* `tests_per_class`: The number of test examples from each class.\n",
    "* `trains_in_test_set`: Include the training examples in the test data. Usually this should be false, but it is useful for checking for overfitting.\n",
    "* `training_labels`: Set to `None` to include data examples across all the labels during training. To just train a subset of networks, provide the labels as a list. For example: `['0','8']`.\n",
    "* `testing_labels`: Set to `None` to include data examples across all the labels during test. To just test a subset of networks, provide the labels as a list. For example: `['0','8']`.\n",
    "* `shuffle`: Set to `False` for class incremental learning. Set to `True` to shuffle the training data. Note that this makes no difference to the test results as the subnetworks learn independently.\n",
    "* `use_edge_detection`: Set to `True` to incorporate a Prewitt edge detection step into the pre-processing. **Note that this was not explored in the paper.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600bf787-e914-4a0e-856a-c487ae775c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = {'dataset': 'mnist_784',  # mnist_784\n",
    "               'trains_per_class': 50,  # 5000,\n",
    "               'tests_per_class': 1222,  # 1000,\n",
    "               'trains_in_test_set': False,\n",
    "               'training_labels': None,  # ['1', '8'], #None, # ['0', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
    "               'testing_labels': None,\n",
    "               'precision_required': 7,\n",
    "               'shuffle': False,\n",
    "               'use_edge_detection': False}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b7361-7bc7-4f5e-8aca-62d104fdb856",
   "metadata": {},
   "source": [
    "## Define where the data should be stored.\n",
    "\n",
    "The example below simply defines a file based on the number of test and training examples. Further granularity may be required if you are experimenting with varying other aspects of the data parameters.\n",
    "\n",
    "If the specified directory already exists, the data saving will fail. This is to prevent overwriting of previously generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c1d627-e33a-49be-ba38-fcfbe1ed77f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = '../datasets'\n",
    "data_sub_dir = 'split_' + str(data_params['dataset'])+'_' +str(data_params['trains_per_class'])+'_'+str(data_params['tests_per_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff124f3-5157-4993-879e-45c723a5e86d",
   "metadata": {},
   "source": [
    "## Generate and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "245f3ce2-3de8-4524-9338-e0e1744cecf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for previously acquired mnist_784 dataset in the folder ../datasets/mnist_784 (Current working dir is /Users/katy/Code/neurogen_classifier/examples)\n",
      "Reading MNIST data from ../datasets/mnist_784/x.npy and ../datasets/mnist_784/y.npy  (Current working dir is /Users/katy/Code/neurogen_classifier/examples)\n",
      "... precision reduced.  to 7 ...\n",
      "mnist_784 data has been loaded. Preparing the training and test examples. ...test and train data has been prepared.\n",
      "Saving train and test examples to directory ../datasets/split_mnist_784_50_1222. Current directory is /Users/katy/Code/neurogen_classifier/examples.\n",
      "Directory ../datasets/split_mnist_784_50_1222 does not exist. Creating it.\n",
      "Data examples and data description saved in directory ../datasets/split_mnist_784_50_1222.\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = get_and_save_train_test_dataset(data_root_dir = data_root_dir, data_sub_dir = data_sub_dir, data_params=data_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40d9e2-aa22-47c3-b9c9-2712dfdc34b1",
   "metadata": {},
   "source": [
    "##Â Using the data\n",
    "\n",
    "To reload the data use:\n",
    "```\n",
    "full_save_dir = os.path.join(data_root_dir, data_sub_dir)\n",
    "utils.mnist_reader.load_train_test_dataset(full_save_dir)\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
